#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø£Ø¯Ø§Ø© ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„Ø© Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø³ÙˆØ±ÙŠØ©
Ø£Ø¯Ø§Ø© Ù…ÙÙŠØ¯Ø© Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© ÙˆØªØ­Ù„ÙŠÙ„ Ø­Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø¨Ø´ÙƒÙ„ Ø¯ÙˆØ±ÙŠ
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime

class KnowledgeBaseAnalyzer:
    def __init__(self):
        self.data_dir = Path("data/syria_knowledge")
        
    def analyze_all_files(self) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©"""
        print("ğŸ” Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø³ÙˆØ±ÙŠØ©...")
        
        analysis_results = {
            "files": {},
            "total_questions": 0,
            "categories": {},
            "quality_metrics": {},
            "compliance_check": {},
            "analysis_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ Ù…Ù„Ù
        for json_file in self.data_dir.glob("*.json"):
            if json_file.name == "analyze_knowledge_base.py":
                continue
            file_analysis = self.analyze_single_file(json_file)
            analysis_results["files"][json_file.name] = file_analysis
            analysis_results["total_questions"] += file_analysis["total_questions"]
            
            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„ÙØ¦Ø©
            category = file_analysis.get("category", "unknown")
            if category not in analysis_results["categories"]:
                analysis_results["categories"][category] = 0
            analysis_results["categories"][category] += file_analysis["total_questions"]
        
        # ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        analysis_results["quality_metrics"] = self.analyze_quality(analysis_results["files"])
        
        # ÙØ­Øµ Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª
        analysis_results["compliance_check"] = self.check_compliance(analysis_results)
        
        return analysis_results
    
    def analyze_single_file(self, file_path: Path) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù ÙˆØ§Ø­Ø¯"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            analysis = {
                "file_name": file_path.name,
                "file_size": file_path.stat().st_size,
                "total_questions": len(data.get("qa_pairs", [])),
                "category": data.get("category", "unknown"),
                "description": data.get("description", ""),
                "version": data.get("version", "unknown"),
                "generated_at": data.get("generated_at", ""),
                "qa_pairs_analysis": self.analyze_qa_pairs(data.get("qa_pairs", [])),
                "structure_compliance": self.check_structure_compliance(data)
            }
            
            return analysis
            
        except Exception as e:
            return {
                "file_name": file_path.name,
                "error": str(e),
                "total_questions": 0
            }
    
    def analyze_qa_pairs(self, qa_pairs: List[Dict]) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø£Ø¬ÙˆØ¨Ø©"""
        if not qa_pairs:
            return {"error": "No QA pairs found"}
        
        analysis = {
            "total_pairs": len(qa_pairs),
            "avg_question_variants": 0,
            "avg_answer_length": 0,
            "avg_keywords_count": 0,
            "confidence_distribution": {},
            "source_distribution": {},
            "language_distribution": {"arabic": 0, "english": 0, "mixed": 0}
        }
        
        total_variants = 0
        total_answer_length = 0
        total_keywords = 0
        
        for qa in qa_pairs:
            # Ø¹Ø¯Ø¯ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø³Ø¤Ø§Ù„
            variants = len(qa.get("question_variants", []))
            total_variants += variants
            
            # Ø·ÙˆÙ„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
            answer_length = len(qa.get("answer", ""))
            total_answer_length += answer_length
            
            # Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
            keywords_count = len(qa.get("keywords", []))
            total_keywords += keywords_count
            
            # ØªÙˆØ²ÙŠØ¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©
            confidence = qa.get("confidence", 0)
            if confidence not in analysis["confidence_distribution"]:
                analysis["confidence_distribution"][confidence] = 0
            analysis["confidence_distribution"][confidence] += 1
            
            # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±
            source = qa.get("source", "unknown")
            if source not in analysis["source_distribution"]:
                analysis["source_distribution"][source] = 0
            analysis["source_distribution"][source] += 1
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù„ØºØ©
            question_text = " ".join(qa.get("question_variants", []))
            answer_text = qa.get("answer", "")
            if self.contains_arabic(question_text) and self.contains_english(question_text):
                analysis["language_distribution"]["mixed"] += 1
            elif self.contains_arabic(question_text):
                analysis["language_distribution"]["arabic"] += 1
            else:
                analysis["language_distribution"]["english"] += 1
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª
        if analysis["total_pairs"] > 0:
            analysis["avg_question_variants"] = total_variants / analysis["total_pairs"]
            analysis["avg_answer_length"] = total_answer_length / analysis["total_pairs"]
            analysis["avg_keywords_count"] = total_keywords / analysis["total_pairs"]
        
        return analysis
    
    def contains_arabic(self, text: str) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù†Øµ Ø¹Ø±Ø¨ÙŠ"""
        arabic_chars = set('Ø§Ø¨ØªØ«Ø¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙŠØ¡Ø¢Ø£Ø¤Ø¥Ø¦')
        return any(char in arabic_chars for char in text)
    
    def contains_english(self, text: str) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù†Øµ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ"""
        english_chars = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')
        return any(char in english_chars for char in text)
    
    def check_structure_compliance(self, data: Dict) -> Dict[str, bool]:
        """ÙØ­Øµ ØªÙˆØ§ÙÙ‚ Ø§Ù„Ø¨Ù†ÙŠØ© Ù…Ø¹ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª"""
        compliance = {
            "has_category": "category" in data,
            "has_description": "description" in data,
            "has_qa_pairs": "qa_pairs" in data,
            "qa_pairs_is_list": isinstance(data.get("qa_pairs"), list),
            "has_total_questions": "total_questions" in data
        }
        
        # ÙØ­Øµ Ø¨Ù†ÙŠØ© Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø£Ø¬ÙˆØ¨Ø©
        if "qa_pairs" in data and isinstance(data["qa_pairs"], list):
            sample_qa = data["qa_pairs"][0] if data["qa_pairs"] else {}
            compliance.update({
                "qa_has_id": "id" in sample_qa,
                "qa_has_question_variants": "question_variants" in sample_qa,
                "qa_has_answer": "answer" in sample_qa,
                "qa_has_keywords": "keywords" in sample_qa,
                "qa_has_confidence": "confidence" in sample_qa,
                "qa_has_source": "source" in sample_qa
            })
        
        return compliance
    
    def analyze_quality(self, files_analysis: Dict) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        quality_metrics = {
            "overall_quality_score": 0,
            "structure_quality": 0,
            "content_quality": 0,
            "language_quality": 0,
            "issues": []
        }
        
        total_files = len(files_analysis)
        structure_score = 0
        content_score = 0
        language_score = 0
        
        for file_name, analysis in files_analysis.items():
            if "error" in analysis:
                quality_metrics["issues"].append(f"Error in {file_name}: {analysis['error']}")
                continue
            
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¨Ù†ÙŠØ©
            compliance = analysis.get("structure_compliance", {})
            structure_score += sum(compliance.values()) / len(compliance) if compliance else 0
            
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø­ØªÙˆÙ‰
            qa_analysis = analysis.get("qa_pairs_analysis", {})
            if qa_analysis.get("total_pairs", 0) > 0:
                content_score += 1  # ÙˆØ¬ÙˆØ¯ Ø£Ø³Ø¦Ù„Ø© ÙˆØ£Ø¬ÙˆØ¨Ø©
                if qa_analysis.get("avg_answer_length", 0) > 20:
                    content_score += 1  # Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…ÙØµÙ„Ø©
                if qa_analysis.get("avg_keywords_count", 0) > 2:
                    content_score += 1  # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© ÙƒØ§ÙÙŠØ©
            
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù„ØºØ©
            lang_dist = qa_analysis.get("language_distribution", {})
            if lang_dist.get("arabic", 0) > 0:
                language_score += 1  # ÙˆØ¬ÙˆØ¯ Ù…Ø­ØªÙˆÙ‰ Ø¹Ø±Ø¨ÙŠ
            if lang_dist.get("mixed", 0) > 0:
                language_score += 1  # ÙˆØ¬ÙˆØ¯ Ù…Ø­ØªÙˆÙ‰ Ø«Ù†Ø§Ø¦ÙŠ Ø§Ù„Ù„ØºØ©
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        if total_files > 0:
            quality_metrics["structure_quality"] = structure_score / total_files
            quality_metrics["content_quality"] = content_score / (total_files * 3)  # 3 Ù…Ø¹Ø§ÙŠÙŠØ± Ù„Ù„Ù…Ø­ØªÙˆÙ‰
            quality_metrics["language_quality"] = language_score / (total_files * 2)  # 2 Ù…Ø¹Ø§ÙŠÙŠØ± Ù„Ù„ØºØ©
            quality_metrics["overall_quality_score"] = (
                quality_metrics["structure_quality"] * 0.3 +
                quality_metrics["content_quality"] * 0.4 +
                quality_metrics["language_quality"] * 0.3
            )
        
        return quality_metrics
    
    def check_compliance(self, analysis_results: Dict) -> Dict[str, Any]:
        """ÙØ­Øµ Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ©"""
        compliance = {
            "meets_quantity_requirement": False,
            "meets_structure_requirement": False,
            "meets_quality_requirement": False,
            "overall_compliance": False,
            "recommendations": []
        }
        
        total_questions = analysis_results["total_questions"]
        
        # ÙØ­Øµ Ù…ØªØ·Ù„Ø¨ Ø§Ù„ÙƒÙ…ÙŠØ© (500-1000 Ø³Ø¤Ø§Ù„)
        if 500 <= total_questions <= 1000:
            compliance["meets_quantity_requirement"] = True
        elif total_questions > 1000:
            compliance["meets_quantity_requirement"] = True
            compliance["recommendations"].append("ØªÙ… ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ - Ù…Ù…ØªØ§Ø²!")
        else:
            compliance["recommendations"].append(f"Ù†Ø­ØªØ§Ø¬ {500 - total_questions} Ø³Ø¤Ø§Ù„ Ø¥Ø¶Ø§ÙÙŠ Ù„Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰")
        
        # ÙØ­Øµ Ù…ØªØ·Ù„Ø¨ Ø§Ù„Ø¨Ù†ÙŠØ©
        required_files = ["cities.json", "government.json", "culture.json", "economy.json", "general.json"]
        existing_files = list(analysis_results["files"].keys())
        missing_files = [f for f in required_files if f not in existing_files]
        
        if not missing_files:
            compliance["meets_structure_requirement"] = True
        else:
            compliance["recommendations"].append(f"Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©: {missing_files}")
        
        # ÙØ­Øµ Ù…ØªØ·Ù„Ø¨ Ø§Ù„Ø¬ÙˆØ¯Ø©
        quality_score = analysis_results["quality_metrics"]["overall_quality_score"]
        if quality_score >= 0.8:
            compliance["meets_quality_requirement"] = True
        else:
            compliance["recommendations"].append(f"ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ - Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {quality_score:.2f}")
        
        # Ø§Ù„ØªÙˆØ§ÙÙ‚ Ø§Ù„Ø¹Ø§Ù…
        compliance["overall_compliance"] = (
            compliance["meets_quantity_requirement"] and
            compliance["meets_structure_requirement"] and
            compliance["meets_quality_requirement"]
        )
        
        return compliance
    
    def generate_report(self, analysis_results: Dict) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„"""
        report = []
        report.append("=" * 60)
        report.append("ğŸ“Š ØªÙ‚Ø±ÙŠØ± ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø³ÙˆØ±ÙŠØ©")
        report.append("=" * 60)
        
        # ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ù„ÙŠÙ„
        report.append(f"\nğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ù„ÙŠÙ„: {analysis_results.get('analysis_date', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
        
        # Ù…Ù„Ø®Øµ Ø¹Ø§Ù…
        report.append(f"\nğŸ¯ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©: {analysis_results['total_questions']}")
        report.append(f"ğŸ“ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª: {len(analysis_results['files'])}")
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª
        report.append("\nğŸ“„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª:")
        for file_name, analysis in analysis_results["files"].items():
            if "error" in analysis:
                report.append(f"  âŒ {file_name}: Ø®Ø·Ø£ - {analysis['error']}")
            else:
                report.append(f"  âœ… {file_name}: {analysis['total_questions']} Ø³Ø¤Ø§Ù„")
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ¦Ø§Øª
        report.append("\nğŸ“‚ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ¦Ø§Øª:")
        for category, count in analysis_results["categories"].items():
            report.append(f"  ğŸ“ {category}: {count} Ø³Ø¤Ø§Ù„")
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬ÙˆØ¯Ø©
        quality = analysis_results["quality_metrics"]
        report.append(f"\nğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬ÙˆØ¯Ø©:")
        report.append(f"  ğŸ“Š Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨Ù†ÙŠØ©: {quality['structure_quality']:.2f}")
        report.append(f"  ğŸ“Š Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {quality['content_quality']:.2f}")
        report.append(f"  ğŸ“Š Ø¬ÙˆØ¯Ø© Ø§Ù„Ù„ØºØ©: {quality['language_quality']:.2f}")
        report.append(f"  ğŸ“Š Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {quality['overall_quality_score']:.2f}")
        
        # ÙØ­Øµ Ø§Ù„ØªÙˆØ§ÙÙ‚
        compliance = analysis_results["compliance_check"]
        report.append(f"\nâœ… ÙØ­Øµ Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª:")
        report.append(f"  ğŸ“Š Ù…ØªØ·Ù„Ø¨ Ø§Ù„ÙƒÙ…ÙŠØ© (500-1000): {'âœ…' if compliance['meets_quantity_requirement'] else 'âŒ'}")
        report.append(f"  ğŸ“Š Ù…ØªØ·Ù„Ø¨ Ø§Ù„Ø¨Ù†ÙŠØ©: {'âœ…' if compliance['meets_structure_requirement'] else 'âŒ'}")
        report.append(f"  ğŸ“Š Ù…ØªØ·Ù„Ø¨ Ø§Ù„Ø¬ÙˆØ¯Ø©: {'âœ…' if compliance['meets_quality_requirement'] else 'âŒ'}")
        report.append(f"  ğŸ“Š Ø§Ù„ØªÙˆØ§ÙÙ‚ Ø§Ù„Ø¹Ø§Ù…: {'âœ…' if compliance['overall_compliance'] else 'âŒ'}")
        
        # Ø§Ù„ØªÙˆØµÙŠØ§Øª
        if compliance["recommendations"]:
            report.append(f"\nğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª:")
            for rec in compliance["recommendations"]:
                report.append(f"  ğŸ’¡ {rec}")
        
        # Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        if compliance["overall_compliance"]:
            report.append(f"\nğŸ‰ Ø§Ù„Ù†ØªÙŠØ¬Ø©: Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª!")
        else:
            report.append(f"\nâš ï¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©: Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© ØªØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†Ø§Øª")
        
        report.append("=" * 60)
        
        return "\n".join(report)

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    print("ğŸ” Ø£Ø¯Ø§Ø© ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø³ÙˆØ±ÙŠØ©")
    print("=" * 50)
    
    analyzer = KnowledgeBaseAnalyzer()
    analysis_results = analyzer.analyze_all_files()
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    report = analyzer.generate_report(analysis_results)
    print(report)
    
    # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ Ù…Ù„Ù Ø«Ø§Ø¨Øª
    report_file = Path("knowledge_base_analysis_report.txt")
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nğŸ“„ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ: {report_file}")
    print(f"ğŸ’¡ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ´ØºÙŠÙ„ Ù‡Ø°Ø§ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª ÙÙŠ Ø£ÙŠ ÙˆÙ‚Øª Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø­Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©")
    print(f"ğŸ“ Ø§Ù„Ù…Ù„Ù Ø³ÙŠØªÙ… ØªØ­Ø¯ÙŠØ«Ù‡ ÙÙŠ ÙƒÙ„ Ù…Ø±Ø© ØªØ´ØºÙ„ ÙÙŠÙ‡Ø§ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª")
    
    return analysis_results

if __name__ == "__main__":
    main()
